{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Multiple Queues in OmniQ\n",
    "\n",
    "This notebook demonstrates how to work with multiple named queues in OmniQ, including priority-based processing where workers process high-priority queues before lower-priority ones.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- **Multiple Named Queues**: Organize tasks into different queues based on priority or type\n",
    "- **Priority-Based Processing**: Workers process queues in order, handling high-priority tasks first\n",
    "- **Queue Management**: Dynamically add, remove, and manage queues\n",
    "- **Flexible Architecture**: All queue backends support multiple queues with consistent APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary modules and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "\n",
    "# Import OmniQ components\n",
    "from omniq.queue import PostgresTaskQueue, SQLiteTaskQueue\n",
    "from omniq.workers import ThreadPoolWorker\n",
    "from omniq.storage import SQLiteResultStorage\n",
    "\n",
    "print(\"‚úì Imports successful\")\n",
    "print(f\"Current time: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Sample Tasks\n",
    "\n",
    "Let's define some sample tasks that we'll use to demonstrate multiple queue functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_task(name, priority_level, duration=1):\n",
    "    \"\"\"A simple task that simulates work and shows which queue it came from.\"\"\"\n",
    "    start_time = datetime.now()\n",
    "    print(f\"[{start_time.strftime('%H:%M:%S')}] Starting {priority_level} priority task: {name}\")\n",
    "    \n",
    "    time.sleep(duration)  # Simulate work\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    print(f\"[{end_time.strftime('%H:%M:%S')}] Completed {priority_level} priority task: {name}\")\n",
    "    \n",
    "    return {\n",
    "        \"task_name\": name,\n",
    "        \"priority\": priority_level,\n",
    "        \"start_time\": start_time.isoformat(),\n",
    "        \"end_time\": end_time.isoformat(),\n",
    "        \"duration\": duration,\n",
    "        \"status\": \"completed\"\n",
    "    }\n",
    "\n",
    "def cpu_intensive_task(name, iterations=1000000):\n",
    "    \"\"\"A CPU-intensive task for demonstration.\"\"\"\n",
    "    print(f\"Starting CPU-intensive task: {name}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Simulate CPU work\n",
    "    total = 0\n",
    "    for i in range(iterations):\n",
    "        total += i * i\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    print(f\"Completed CPU-intensive task: {name} (took {duration:.2f}s)\")\n",
    "    \n",
    "    return {\n",
    "        \"task_name\": name,\n",
    "        \"type\": \"cpu_intensive\",\n",
    "        \"iterations\": iterations,\n",
    "        \"result\": total,\n",
    "        \"duration\": duration\n",
    "    }\n",
    "\n",
    "def io_simulation_task(name, delay=2):\n",
    "    \"\"\"An I/O task that simulates network or file operations.\"\"\"\n",
    "    print(f\"Starting I/O simulation task: {name}\")\n",
    "    time.sleep(delay)  # Simulate I/O wait\n",
    "    print(f\"Completed I/O simulation task: {name}\")\n",
    "    \n",
    "    return {\n",
    "        \"task_name\": name,\n",
    "        \"type\": \"io_simulation\",\n",
    "        \"delay\": delay,\n",
    "        \"status\": \"completed\"\n",
    "    }\n",
    "\n",
    "print(\"‚úì Task functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Multiple Queue Setup\n",
    "\n",
    "Now let's create a task queue with multiple named queues and set up our worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SQLite queue with multiple named queues for this demo\n",
    "# Queues are processed in priority order: critical -> high -> medium -> low\n",
    "queue = SQLiteTaskQueue(\n",
    "    project_name=\"multiple_queues_demo\",\n",
    "    base_dir=\"./demo_data\",\n",
    "    queues=[\"critical\", \"high\", \"medium\", \"low\"]\n",
    ")\n",
    "\n",
    "# Create result storage\n",
    "result_store = SQLiteResultStorage(\n",
    "    project_name=\"multiple_queues_demo\",\n",
    "    base_dir=\"./demo_data\"\n",
    ")\n",
    "\n",
    "# Create worker that processes queues in priority order\n",
    "worker = ThreadPoolWorker(\n",
    "    queue=queue,\n",
    "    result_store=result_store,\n",
    "    max_workers=4  # Use fewer workers for clearer demonstration\n",
    ")\n",
    "\n",
    "print(\"‚úì Queue, result store, and worker created\")\n",
    "print(f\"Available queues: {queue.get_queue_names()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate Priority-Based Processing\n",
    "\n",
    "Let's enqueue tasks to different priority queues and observe how they are processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Priority-Based Processing Demonstration ===\")\n",
    "print(\"We'll enqueue tasks to different queues and see the processing order.\\n\")\n",
    "\n",
    "# Start the worker\n",
    "worker.start()\n",
    "print(\"‚úì Worker started\\n\")\n",
    "\n",
    "# Enqueue tasks to different priority queues\n",
    "task_ids = []\n",
    "\n",
    "print(\"Enqueuing tasks to different priority queues...\")\n",
    "\n",
    "# Low priority tasks (will be processed last)\n",
    "for i in range(2):\n",
    "    task_id = queue.enqueue(\n",
    "        func=simple_task,\n",
    "        func_args={\n",
    "            \"name\": f\"LowTask-{i+1}\",\n",
    "            \"priority_level\": \"LOW\",\n",
    "            \"duration\": 1\n",
    "        },\n",
    "        queue_name=\"low\"\n",
    "    )\n",
    "    task_ids.append((\"low\", task_id))\n",
    "    print(f\"  üìù Enqueued LOW priority task: LowTask-{i+1}\")\n",
    "\n",
    "# Medium priority tasks\n",
    "for i in range(2):\n",
    "    task_id = queue.enqueue(\n",
    "        func=simple_task,\n",
    "        func_args={\n",
    "            \"name\": f\"MediumTask-{i+1}\",\n",
    "            \"priority_level\": \"MEDIUM\",\n",
    "            \"duration\": 1\n",
    "        },\n",
    "        queue_name=\"medium\"\n",
    "    )\n",
    "    task_ids.append((\"medium\", task_id))\n",
    "    print(f\"  üìù Enqueued MEDIUM priority task: MediumTask-{i+1}\")\n",
    "\n",
    "# High priority tasks\n",
    "for i in range(2):\n",
    "    task_id = queue.enqueue(\n",
    "        func=simple_task,\n",
    "        func_args={\n",
    "            \"name\": f\"HighTask-{i+1}\",\n",
    "            \"priority_level\": \"HIGH\",\n",
    "            \"duration\": 1\n",
    "        },\n",
    "        queue_name=\"high\"\n",
    "    )\n",
    "    task_ids.append((\"high\", task_id))\n",
    "    print(f\"  üìù Enqueued HIGH priority task: HighTask-{i+1}\")\n",
    "\n",
    "# Critical priority tasks (will be processed first)\n",
    "for i in range(2):\n",
    "    task_id = queue.enqueue(\n",
    "        func=simple_task,\n",
    "        func_args={\n",
    "            \"name\": f\"CriticalTask-{i+1}\",\n",
    "            \"priority_level\": \"CRITICAL\",\n",
    "            \"duration\": 1\n",
    "        },\n",
    "        queue_name=\"critical\"\n",
    "    )\n",
    "    task_ids.append((\"critical\", task_id))\n",
    "    print(f\"  üìù Enqueued CRITICAL priority task: CriticalTask-{i+1}\")\n",
    "\n",
    "print(f\"\\nüìä Total tasks enqueued: {len(task_ids)}\")\n",
    "print(\"\\n‚è≥ Watch the execution order - CRITICAL tasks should run first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait for Tasks and Collect Results\n",
    "\n",
    "Let's wait for all tasks to complete and examine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Collecting Results ===\")\n",
    "\n",
    "# Wait for all tasks to complete and collect results\n",
    "completed_tasks = []\n",
    "failed_tasks = []\n",
    "\n",
    "for queue_name, task_id in task_ids:\n",
    "    try:\n",
    "        # Wait for result with timeout\n",
    "        result = result_store.get(task_id, timeout=30)\n",
    "        completed_tasks.append((queue_name, task_id, result))\n",
    "        print(f\"‚úÖ {queue_name.upper()} queue task completed: {result['task_name']}\")\n",
    "    except Exception as e:\n",
    "        failed_tasks.append((queue_name, task_id, str(e)))\n",
    "        print(f\"‚ùå Task {task_id} failed: {e}\")\n",
    "\n",
    "print(f\"\\nüìà Summary:\")\n",
    "print(f\"   - Total tasks enqueued: {len(task_ids)}\")\n",
    "print(f\"   - Tasks completed: {len(completed_tasks)}\")\n",
    "print(f\"   - Tasks failed: {len(failed_tasks)}\")\n",
    "\n",
    "# Show queue-specific statistics\n",
    "queue_stats = {}\n",
    "for queue_name, task_id, result in completed_tasks:\n",
    "    if queue_name not in queue_stats:\n",
    "        queue_stats[queue_name] = 0\n",
    "    queue_stats[queue_name] += 1\n",
    "\n",
    "print(f\"\\nüìä Tasks completed by queue:\")\n",
    "for queue_name in [\"critical\", \"high\", \"medium\", \"low\"]:\n",
    "    count = queue_stats.get(queue_name, 0)\n",
    "    print(f\"   - {queue_name.upper()}: {count} tasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate Different Task Types\n",
    "\n",
    "Now let's demonstrate how different types of tasks can be organized into appropriate queues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Different Task Types Demonstration ===\")\n",
    "print(\"Organizing different task types into appropriate priority queues...\\n\")\n",
    "\n",
    "# Clear any remaining tasks and reset\n",
    "time.sleep(2)  # Give previous tasks time to complete\n",
    "\n",
    "task_ids_by_type = []\n",
    "\n",
    "# Critical system task - goes to critical queue\n",
    "critical_task_id = queue.enqueue(\n",
    "    func=cpu_intensive_task,\n",
    "    func_args={\"name\": \"SystemHealthCheck\", \"iterations\": 500000},\n",
    "    queue_name=\"critical\"\n",
    ")\n",
    "task_ids_by_type.append((\"critical\", \"system\", critical_task_id))\n",
    "print(\"üö® Enqueued CRITICAL system health check\")\n",
    "\n",
    "# User-facing task - goes to high priority queue\n",
    "user_task_id = queue.enqueue(\n",
    "    func=simple_task,\n",
    "    func_args={\n",
    "        \"name\": \"UserRequest\",\n",
    "        \"priority_level\": \"HIGH\",\n",
    "        \"duration\": 1\n",
    "    },\n",
    "    queue_name=\"high\"\n",
    ")\n",
    "task_ids_by_type.append((\"high\", \"user\", user_task_id))\n",
    "print(\"üë§ Enqueued HIGH priority user request\")\n",
    "\n",
    "# Background sync - goes to medium priority queue\n",
    "sync_task_id = queue.enqueue(\n",
    "    func=io_simulation_task,\n",
    "    func_args={\"name\": \"DataSync\", \"delay\": 2},\n",
    "    queue_name=\"medium\"\n",
    ")\n",
    "task_ids_by_type.append((\"medium\", \"background\", sync_task_id))\n",
    "print(\"üîÑ Enqueued MEDIUM priority background sync\")\n",
    "\n",
    "# Cleanup task - goes to low priority queue\n",
    "cleanup_task_id = queue.enqueue(\n",
    "    func=simple_task,\n",
    "    func_args={\n",
    "        \"name\": \"LogCleanup\",\n",
    "        \"priority_level\": \"LOW\",\n",
    "        \"duration\": 1\n",
    "    },\n",
    "    queue_name=\"low\"\n",
    ")\n",
    "task_ids_by_type.append((\"low\", \"maintenance\", cleanup_task_id))\n",
    "print(\"üßπ Enqueued LOW priority cleanup task\")\n",
    "\n",
    "print(f\"\\nüìù Enqueued {len(task_ids_by_type)} different task types\")\n",
    "print(\"‚è≥ Observing execution order based on queue priority...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor Task Execution\n",
    "\n",
    "Let's monitor the execution of our different task types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Monitoring Task Execution ===\")\n",
    "\n",
    "# Wait for tasks and collect results\n",
    "type_results = []\n",
    "\n",
    "for queue_name, task_type, task_id in task_ids_by_type:\n",
    "    try:\n",
    "        result = result_store.get(task_id, timeout=30)\n",
    "        type_results.append((queue_name, task_type, result))\n",
    "        \n",
    "        if isinstance(result, dict) and 'task_name' in result:\n",
    "            print(f\"‚úÖ {queue_name.upper()} ({task_type}): {result['task_name']} completed\")\n",
    "        else:\n",
    "            print(f\"‚úÖ {queue_name.upper()} ({task_type}): Task completed\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {queue_name.upper()} ({task_type}) task failed: {e}\")\n",
    "\n",
    "print(f\"\\nüìä Task Type Execution Summary:\")\n",
    "for queue_name, task_type, result in type_results:\n",
    "    print(f\"   - {task_type.capitalize()} task ({queue_name} priority): ‚úÖ Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue Management Operations\n",
    "\n",
    "Let's demonstrate dynamic queue management capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Queue Management Operations ===\")\n",
    "\n",
    "# Show current queues\n",
    "current_queues = queue.get_queue_names()\n",
    "print(f\"üìã Current queues: {current_queues}\")\n",
    "\n",
    "# Check queue sizes\n",
    "print(f\"\\nüìä Current queue sizes:\")\n",
    "for queue_name in current_queues:\n",
    "    try:\n",
    "        size = queue.get_queue_size(queue_name)\n",
    "        print(f\"   - {queue_name}: {size} tasks\")\n",
    "    except Exception as e:\n",
    "        print(f\"   - {queue_name}: Error getting size - {e}\")\n",
    "\n",
    "# Add a new queue dynamically\n",
    "print(f\"\\n‚ûï Adding new 'urgent' queue...\")\n",
    "try:\n",
    "    queue.add_queue(\"urgent\")\n",
    "    updated_queues = queue.get_queue_names()\n",
    "    print(f\"‚úÖ Updated queues: {updated_queues}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to add queue: {e}\")\n",
    "\n",
    "# Enqueue a task to the new queue\n",
    "try:\n",
    "    urgent_task_id = queue.enqueue(\n",
    "        func=simple_task,\n",
    "        func_args={\n",
    "            \"name\": \"UrgentTask\",\n",
    "            \"priority_level\": \"URGENT\",\n",
    "            \"duration\": 1\n",
    "        },\n",
    "        queue_name=\"urgent\"\n",
    "    )\n",
    "    print(f\"üöÄ Enqueued task to new 'urgent' queue\")\n",
    "    \n",
    "    # Wait for the urgent task to complete\n",
    "    urgent_result = result_store.get(urgent_task_id, timeout=15)\n",
    "    print(f\"‚úÖ Urgent task completed: {urgent_result['task_name']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error with urgent queue task: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup and Summary\n",
    "\n",
    "Let's clean up our resources and summarize what we've learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Cleanup and Summary ===\")\n",
    "\n",
    "# Stop the worker\n",
    "print(\"üõë Stopping worker...\")\n",
    "worker.stop()\n",
    "print(\"‚úÖ Worker stopped successfully\")\n",
    "\n",
    "# Final queue status\n",
    "final_queues = queue.get_queue_names()\n",
    "print(f\"\\nüìã Final queue configuration: {final_queues}\")\n",
    "\n",
    "print(f\"\\nüéØ Key Takeaways:\")\n",
    "print(f\"   1. ‚úÖ Tasks are processed in queue priority order\")\n",
    "print(f\"   2. ‚úÖ Workers exhaust higher priority queues before moving to lower ones\")\n",
    "print(f\"   3. ‚úÖ Different task types can be organized by priority and purpose\")\n",
    "print(f\"   4. ‚úÖ Queues can be managed dynamically (add/remove)\")\n",
    "print(f\"   5. ‚úÖ All queue backends support multiple queues with consistent APIs\")\n",
    "\n",
    "print(f\"\\nüèÜ Multiple Queues Demo Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Async Multiple Queues\n",
    "\n",
    "Let's also demonstrate the async interface for multiple queues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_multiple_queues_demo():\n",
    "    \"\"\"Demonstrate async multiple queues functionality.\"\"\"\n",
    "    print(\"\\n=== Async Multiple Queues Demo ===\")\n",
    "    \n",
    "    from omniq.queue import AsyncSQLiteTaskQueue\n",
    "    from omniq.workers import AsyncWorker\n",
    "    from omniq.storage import AsyncSQLiteResultStorage\n",
    "    \n",
    "    # Create async components\n",
    "    async_queue = AsyncSQLiteTaskQueue(\n",
    "        project_name=\"async_multiple_queues\",\n",
    "        base_dir=\"./async_demo_data\",\n",
    "        queues=[\"priority1\", \"priority2\", \"priority3\"]\n",
    "    )\n",
    "    \n",
    "    async_result_store = AsyncSQLiteResultStorage(\n",
    "        project_name=\"async_multiple_queues\",\n",
    "        base_dir=\"./async_demo_data\"\n",
    "    )\n",
    "    \n",
    "    async_worker = AsyncWorker(\n",
    "        queue=async_queue,\n",
    "        result_store=async_result_store,\n",
    "        max_workers=3\n",
    "    )\n",
    "    \n",
    "    async def async_task(name, priority):\n",
    "        \"\"\"An async task for demonstration.\"\"\"\n",
    "        print(f\"üîÑ Processing async {priority} task: {name}\")\n",
    "        await asyncio.sleep(1)  # Simulate async I/O\n",
    "        print(f\"‚úÖ Completed async {priority} task: {name}\")\n",
    "        return f\"Async {priority} task {name} completed\"\n",
    "    \n",
    "    try:\n",
    "        print(\"üöÄ Starting async worker...\")\n",
    "        await async_worker.start()\n",
    "        \n",
    "        print(\"üìù Enqueuing async tasks to different queues...\")\n",
    "        \n",
    "        # Enqueue tasks to different priority queues\n",
    "        async_task_ids = []\n",
    "        \n",
    "        # Priority 1 tasks (highest priority)\n",
    "        for i in range(2):\n",
    "            task_id = await async_queue.enqueue(\n",
    "                func=async_task,\n",
    "                func_args={\"name\": f\"AsyncP1-{i+1}\", \"priority\": \"P1\"},\n",
    "                queue_name=\"priority1\"\n",
    "            )\n",
    "            async_task_ids.append(task_id)\n",
    "            print(f\"   üìå Enqueued P1 async task: AsyncP1-{i+1}\")\n",
    "        \n",
    "        # Priority 2 tasks\n",
    "        for i in range(2):\n",
    "            task_id = await async_queue.enqueue(\n",
    "                func=async_task,\n",
    "                func_args={\"name\": f\"AsyncP2-{i+1}\", \"priority\": \"P2\"},\n",
    "                queue_name=\"priority2\"\n",
    "            )\n",
    "            async_task_ids.append(task_id)\n",
    "            print(f\"   üìå Enqueued P2 async task: AsyncP2-{i+1}\")\n",
    "        \n",
    "        # Priority 3 tasks (lowest priority)\n",
    "        for i in range(2):\n",
    "            task_id = await async_queue.enqueue(\n",
    "                func=async_task,\n",
    "                func_args={\"name\": f\"AsyncP3-{i+1}\", \"priority\": \"P3\"},\n",
    "                queue_name=\"priority3\"\n",
    "            )\n",
    "            async_task_ids.append(task_id)\n",
    "            print(f\"   üìå Enqueued P3 async task: AsyncP3-{i+1}\")\n",
    "        \n",
    "        print(f\"\\n‚è≥ Waiting for {len(async_task_ids)} async tasks to complete...\")\n",
    "        \n",
    "        # Wait for all tasks to complete\n",
    "        completed_async = 0\n",
    "        for task_id in async_task_ids:\n",
    "            try:\n",
    "                result = await async_result_store.get(task_id, timeout=30)\n",
    "                completed_async += 1\n",
    "                print(f\"   ‚úÖ Async task completed: {result}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Async task {task_id} failed: {e}\")\n",
    "        \n",
    "        print(f\"\\nüéØ Async demo summary: {completed_async}/{len(async_task_ids)} tasks completed\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in async demo: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        print(\"üõë Stopping async worker...\")\n",
    "        await async_worker.stop()\n",
    "        print(\"‚úÖ Async worker stopped\")\n",
    "\n",
    "# Run the async demo\n",
    "await async_multiple_queues_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the key features of working with multiple queues in OmniQ:\n",
    "\n",
    "### ‚úÖ What We Learned\n",
    "\n",
    "1. **Priority-Based Processing**: Tasks in higher-priority queues are processed before lower-priority ones\n",
    "2. **Queue Organization**: Different types of tasks can be organized into appropriate queues\n",
    "3. **Dynamic Management**: Queues can be added and managed dynamically\n",
    "4. **Consistent API**: Both sync and async interfaces support multiple queues\n",
    "5. **Flexible Architecture**: All queue backends support multiple queues\n",
    "\n",
    "### 