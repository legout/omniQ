[
  {
    "objectID": "api/task_queues.html",
    "href": "api/task_queues.html",
    "title": "Task Queues",
    "section": "",
    "text": "This section covers the different task queue implementations available in OmniQ.\nOmniQ supports multiple backends for task queues. Each backend has a sync and an async version. For more information on configuring backends, see ?@sec-backends."
  },
  {
    "objectID": "api/task_queues.html#available-task-queues",
    "href": "api/task_queues.html#available-task-queues",
    "title": "Task Queues",
    "section": "Available Task Queues",
    "text": "Available Task Queues\n\n\n\nQueue Type\nSynchronous Class\nAsynchronous Class\n\n\n\n\nFile\nomniq.queue.file.FileQueue\nomniq.queue.file.AsyncFileQueue\n\n\nMemory\nomniq.queue.memory.MemoryQueue\nomniq.queue.memory.AsyncMemoryQueue\n\n\nSQLite\nomniq.queue.sqlite.SQLiteQueue\nomniq.queue.sqlite.AsyncSQLiteQueue\n\n\nPostgreSQL\nomniq.queue.postgres.PostgresQueue\nomniq.queue.postgres.AsyncPostgresQueue\n\n\nRedis\nomniq.queue.redis.RedisQueue\nomniq.queue.redis.AsyncRedisQueue\n\n\nNATS\nomniq.queue.nats.NATSQueue\nomniq.queue.nats.AsyncNATSQueue\n\n\n\n\nIn-Memory Queue\nThe in-memory queue is useful for testing and scenarios where persistence is not required.\n\n\n\n\n\n\nWarning\n\n\n\nThe in-memory queue is not persistent. If the application restarts, all tasks in the queue will be lost."
  },
  {
    "objectID": "api/task_queues.html#multiple-named-queues",
    "href": "api/task_queues.html#multiple-named-queues",
    "title": "Task Queues",
    "section": "Multiple Named Queues",
    "text": "Multiple Named Queues\nAll task queue implementations support multiple named queues, allowing you to prioritize and segregate tasks.\n\nFile Queue: Uses a directory structure for each queue.\nSQLite/PostgreSQL Queue: Uses a queue column with priority ordering.\nRedis Queue: Uses queue prefixes.\nNATS Queue: Uses subject prefixes.\n\n\nUsage\nYou can specify the queues when creating a TaskQueue instance.\nfrom omniq import TaskQueue\nfrom omniq.queue import SQLiteQueue\n\n# Create a task queue with multiple named queues\ntask_queue = TaskQueue(\n    queue=SQLiteQueue(project_name=\"my_project\"),\n    queues=[\"high\", \"medium\", \"low\"]\n)\n\n# Enqueue a task to a specific queue\n@oq.task(queue=\"high\")\ndef my_high_priority_task():\n    # ...\n    pass\nPlaceholder for more advanced queueing strategies."
  },
  {
    "objectID": "getting_started.html",
    "href": "getting_started.html",
    "title": "Getting Started",
    "section": "",
    "text": "This page will guide you through the process of setting up and using OmniQ.\n\n\nfrom omniq import AsyncOmniQ\nfrom omniq.queue import FileTaskQueue\nfrom omniq.storage import SQLiteResultStorage, PostgresEventStorage\nimport datetime as dt\n\n# Create AsyncOmniQ instance with default components\noq = AsyncOmniQ(\n    project_name=\"my_project\",\n    task_queue=FileTaskQueue(base_dir=\"some/path\", queues=[\"low\", \"medium\", \"high\"]),\n    result_store=SQLiteResultStorage(base_dir=\"some/path\"),\n    event_store=PostgresEventStorage(host=\"localhost\", port=5432, username=\"postgres\")\n)\n\n# Define an async task\nasync def async_task(name):\n    print(f\"Hello {name}\")\n    return name\n\n# Start the worker\nawait oq.start_worker()\n\n# Enqueue a task\ntask_id = await oq.enqueue(\n    func=async_task,\n    func_args=dict(name=\"Tom\"),\n    queue_name=\"low\",\n    run_in=dt.timedelta(seconds=100),\n    ttl=dt.timedelta(hours=1),\n    result_ttl=dt.timedelta(minutes=5)\n)\n\n# Get the result\nresult = await oq.get_result(task_id)\n\n# Schedule a recurring task\nschedule_id = await oq.schedule(\n    func=async_task,\n    func_args=dict(name=\"Tom\"),\n    interval=dt.timedelta(seconds=10),\n    queue_name=\"low\"\n)\n\n# Get latest result from scheduled task\nlatest_result = await oq.get_result(schedule_id=schedule_id, kind=\"latest\")\n\n# Stop the worker\nawait oq.stop_worker()\n\n# Using async context manager\nasync with AsyncOmniQ(...) as oq:\n    task_id = await oq.enqueue(async_task, func_args=dict(name=\"Tom\"))\n    result = await oq.get_result(task_id)\n\n\n\nfrom omniq import OmniQ\nfrom omniq.queue import FileTaskQueue\nfrom omniq.storage import SQLiteResultStorage, PostgresEventStorage\nimport datetime as dt\n\n# Create OmniQ instance with default components\noq = OmniQ(\n    project_name=\"my_project\",\n    task_queue=FileTaskQueue(base_dir=\"some/path\", queues=[\"low\", \"medium\", \"high\"]),\n    result_store=SQLiteResultStorage(base_dir=\"some/path\"),\n    event_store=PostgresEventStorage(host=\"localhost\", port=5432, username=\"postgres\")\n)\n\n# Define a task\ndef simple_task(name):\n    print(f\"Hello {name}\")\n    return name\n\n# Start the worker\noq.start_worker()\n\n# Enqueue a task\ntask_id = oq.enqueue(\n    func=simple_task,\n    func_args=dict(name=\"Tom\"),\n    queue_name=\"low\",\n    run_in=dt.timedelta(seconds=100),\n    ttl=dt.timedelta(hours=1),\n    result_ttl=dt.timedelta(minutes=5)\n)\n\n# Get the result\nresult = oq.get_result(task_id)\n\n# Schedule a recurring task\nschedule_id = oq.schedule(\n    func=simple_task,\n    func_args=dict(name=\"Tom\"),\n    interval=dt.timedelta(seconds=10),\n    queue_name=\"low\"\n)\n\n# Get latest result from scheduled task\nlatest_result = oq.get_result(schedule_id=schedule_id, kind=\"latest\")\n\n# Stop the worker\noq.stop_worker()\n\n# Using sync context manager\nwith OmniQ(...) as oq:\n    task_id = oq.enqueue(simple_task, func_args=dict(name=\"Tom\"))\n    result = oq.get_result(task_id)"
  },
  {
    "objectID": "getting_started.html#basic-usage-with-asyncomniq",
    "href": "getting_started.html#basic-usage-with-asyncomniq",
    "title": "Getting Started",
    "section": "",
    "text": "from omniq import AsyncOmniQ\nfrom omniq.queue import FileTaskQueue\nfrom omniq.storage import SQLiteResultStorage, PostgresEventStorage\nimport datetime as dt\n\n# Create AsyncOmniQ instance with default components\noq = AsyncOmniQ(\n    project_name=\"my_project\",\n    task_queue=FileTaskQueue(base_dir=\"some/path\", queues=[\"low\", \"medium\", \"high\"]),\n    result_store=SQLiteResultStorage(base_dir=\"some/path\"),\n    event_store=PostgresEventStorage(host=\"localhost\", port=5432, username=\"postgres\")\n)\n\n# Define an async task\nasync def async_task(name):\n    print(f\"Hello {name}\")\n    return name\n\n# Start the worker\nawait oq.start_worker()\n\n# Enqueue a task\ntask_id = await oq.enqueue(\n    func=async_task,\n    func_args=dict(name=\"Tom\"),\n    queue_name=\"low\",\n    run_in=dt.timedelta(seconds=100),\n    ttl=dt.timedelta(hours=1),\n    result_ttl=dt.timedelta(minutes=5)\n)\n\n# Get the result\nresult = await oq.get_result(task_id)\n\n# Schedule a recurring task\nschedule_id = await oq.schedule(\n    func=async_task,\n    func_args=dict(name=\"Tom\"),\n    interval=dt.timedelta(seconds=10),\n    queue_name=\"low\"\n)\n\n# Get latest result from scheduled task\nlatest_result = await oq.get_result(schedule_id=schedule_id, kind=\"latest\")\n\n# Stop the worker\nawait oq.stop_worker()\n\n# Using async context manager\nasync with AsyncOmniQ(...) as oq:\n    task_id = await oq.enqueue(async_task, func_args=dict(name=\"Tom\"))\n    result = await oq.get_result(task_id)"
  },
  {
    "objectID": "getting_started.html#basic-usage-with-omniq-sync",
    "href": "getting_started.html#basic-usage-with-omniq-sync",
    "title": "Getting Started",
    "section": "",
    "text": "from omniq import OmniQ\nfrom omniq.queue import FileTaskQueue\nfrom omniq.storage import SQLiteResultStorage, PostgresEventStorage\nimport datetime as dt\n\n# Create OmniQ instance with default components\noq = OmniQ(\n    project_name=\"my_project\",\n    task_queue=FileTaskQueue(base_dir=\"some/path\", queues=[\"low\", \"medium\", \"high\"]),\n    result_store=SQLiteResultStorage(base_dir=\"some/path\"),\n    event_store=PostgresEventStorage(host=\"localhost\", port=5432, username=\"postgres\")\n)\n\n# Define a task\ndef simple_task(name):\n    print(f\"Hello {name}\")\n    return name\n\n# Start the worker\noq.start_worker()\n\n# Enqueue a task\ntask_id = oq.enqueue(\n    func=simple_task,\n    func_args=dict(name=\"Tom\"),\n    queue_name=\"low\",\n    run_in=dt.timedelta(seconds=100),\n    ttl=dt.timedelta(hours=1),\n    result_ttl=dt.timedelta(minutes=5)\n)\n\n# Get the result\nresult = oq.get_result(task_id)\n\n# Schedule a recurring task\nschedule_id = oq.schedule(\n    func=simple_task,\n    func_args=dict(name=\"Tom\"),\n    interval=dt.timedelta(seconds=10),\n    queue_name=\"low\"\n)\n\n# Get latest result from scheduled task\nlatest_result = oq.get_result(schedule_id=schedule_id, kind=\"latest\")\n\n# Stop the worker\noq.stop_worker()\n\n# Using sync context manager\nwith OmniQ(...) as oq:\n    task_id = oq.enqueue(simple_task, func_args=dict(name=\"Tom\"))\n    result = oq.get_result(task_id)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OmniQ: A Flexible Task Queue Library for Python",
    "section": "",
    "text": "OmniQ is a modular Python task queue library designed for both local and distributed task processing. It provides a flexible architecture that supports multiple storage backends, worker types, and configuration methods. OmniQ enables developers to easily implement task queuing, scheduling, and distributed processing in their applications with both synchronous and asynchronous interfaces."
  },
  {
    "objectID": "index.html#key-features",
    "href": "index.html#key-features",
    "title": "OmniQ: A Flexible Task Queue Library for Python",
    "section": "Key Features",
    "text": "Key Features\n\nMultiple Storage Backends: Supports File, Memory, SQLite, PostgreSQL, Redis, and NATS.\nMultiple Worker Types: Includes Async, Thread Pool, Process Pool, and Gevent workers.\nSync and Async Interfaces: Provides both synchronous and asynchronous APIs.\nAdvanced Task Scheduling: Cron and interval patterns with pause/resume capabilities.\nTask Dependencies: Manage complex workflows.\nEvent Logging: In-depth task lifecycle event logging.\nFlexible Configuration: Configure via code, objects, YAML, or environment variables.\nCloud Storage: fsspec integration for cloud storage (S3, Azure, GCP)."
  },
  {
    "objectID": "index.html#get-started",
    "href": "index.html#get-started",
    "title": "OmniQ: A Flexible Task Queue Library for Python",
    "section": "Get Started",
    "text": "Get Started\nTo get started with OmniQ, check out the Quickstart Guide."
  },
  {
    "objectID": "advanced.html",
    "href": "advanced.html",
    "title": "Advanced Usage",
    "section": "",
    "text": "OmniQ is designed with flexibility in mind, offering advanced configuration options and features to handle complex, real-world scenarios. This guide covers some of the more sophisticated capabilities, including advanced configuration, handling mixed synchronous and asynchronous tasks, and integrating with cloud storage solutions.\n\n\nWhile you can instantiate OmniQ components directly, a configuration-driven approach offers greater flexibility, especially in production environments. This allows you to define your setup in YAML files, dictionaries, or even environment variables, decoupling your application logic from your infrastructure setup.\n\n\nFor maximum clarity and maintainability, we recommend using a YAML file to define your OmniQ setup. This approach allows you to specify the project name, task queue, result store, and worker settings in a single, easy-to-read file.\nHere’s an example of a config.yaml file:\nproject_name: production_app\n\ntask_queue:\n  type: file\n  config:\n    base_dir: ./omniq_data/tasks\n    queues:\n      - high_priority\n      - default\n      - low_priority\n\nresult_store:\n  type: sqlite\n  config:\n    base_dir: ./omniq_data/results\n\nworker:\n  type: thread_pool\n  config:\n    max_workers: 10\nYou can then load this configuration and create an OmniQ instance with a single command:\nfrom omniq import OmniQ\n\n# Load the configuration from the YAML file\noq = OmniQ.from_config_file(\"config.yaml\")\n\n# Now your OmniQ instance is ready to use\nwith oq:\n    # Enqueue tasks, manage workers, etc.\n    pass\n\n\n\nFor cloud-native applications and CI/CD pipelines, you can override configuration settings using environment variables. OmniQ recognizes variables prefixed with OMNIQ_.\nFor example, to override the worker’s max_workers setting, you can set the following environment variable:\nexport OMNIQ_WORKER_CONFIG_MAX_WORKERS=20\nOmniQ will automatically detect and apply this setting. For more details on configuration loading and precedence, see the configuration API documentation.\n\n\n\n\nModern applications often require a mix of synchronous (CPU-bound) and asynchronous (I/O-bound) tasks. OmniQ’s workers are designed to handle both types of tasks seamlessly within the same queue, simplifying your architecture.\nBoth ThreadWorker and AsyncWorker can execute sync and async functions without any special configuration. The worker automatically detects whether a task function is a coroutine and executes it accordingly.\nimport asyncio\nimport time\nfrom omniq import OmniQ\nfrom omniq.queue import FileTaskQueue\n\n# A standard synchronous function\ndef sync_task(x, y):\n    print(f\"Executing sync task: {x} * {y}\")\n    time.sleep(0.1)\n    return x * y\n\n# An asynchronous function\nasync def async_task(x, y):\n    print(f\"Executing async task: {x} + {y}\")\n    await asyncio.sleep(0.1)\n    return x + y\n\n# Setup OmniQ (can be done via config file as well)\noq = OmniQ(project_name=\"mixed_tasks_example\")\n\nwith oq:\n    # Enqueue both types of tasks\n    sync_task_id = oq.enqueue(sync_task, func_args={'x': 5, 'y': 10})\n    async_task_id = oq.enqueue(async_task, func_args={'x': 5, 'y': 10})\n\n    # Wait for results\n    time.sleep(1)\n\n    # Retrieve results - the worker handles both correctly\n    sync_result = oq.get_result(sync_task_id)    # -&gt; 50\n    async_result = oq.get_result(async_task_id) # -&gt; 15\n\n    print(f\"Sync Result: {sync_result}\")\n    print(f\"Async Result: {async_result}\")\nThis flexibility allows you to build versatile applications that can handle a wide variety of workloads without needing separate task processing systems.\n\n\n\nOmniQ’s FileTaskQueue and FileResultStorage components are built on top of the fsspec (Filesystem Spec) library. This powerful abstraction allows you to use virtually any storage backend that fsspec supports, including cloud storage providers like Amazon S3, Google Cloud Storage (GCS), and Azure Blob Storage.\nTo use a cloud storage backend, simply provide the appropriate URI in the base_dir and include any necessary credentials in the storage_options dictionary.\n\n\nFirst, ensure you have the required library installed:\npip install s3fs\nThen, configure the FileTaskQueue to use an S3 bucket:\nfrom omniq.queue import FileTaskQueue\n\n# Configuration for S3 storage\ns3_queue = FileTaskQueue(\n    project_name=\"s3_demo\",\n    base_dir=\"s3://your-cool-bucket/omniq/tasks\",\n    storage_options={\n        \"key\": \"YOUR_AWS_ACCESS_KEY_ID\",\n        \"secret\": \"YOUR_AWS_SECRET_ACCESS_KEY\",\n    }\n)\n\n# You can now use this queue with your OmniQ instance\n# oq = OmniQ(project_name=\"s3_demo\", task_queue=s3_queue, ...)\nThe same principle applies to FileResultStorage and other cloud providers like GCS (gs://...) and Azure Blob Storage (abfs://...).\nThis integration makes it easy to build distributed, scalable applications where tasks and results are persisted in a centralized, durable, and highly-available cloud storage service.\n\n\n\n\n\nChoose the Right Worker: Use ThreadWorker for I/O-bound synchronous tasks. For async tasks, AsyncWorker is generally more efficient as it can handle thousands of concurrent operations with a small number of threads.\nSerialization: The default serializer (dill) is very flexible but may not be the fastest. For performance-critical applications with well-defined data structures, consider using a faster serializer like msgspec.\nBatching: When enqueuing a large number of tasks, consider using enqueue_many to reduce the overhead of individual network requests or disk I/O operations.\nPersistent Connections: When using network-based backends (like Redis or a database), ensure your application manages connections efficiently. OmniQ’s built-in components handle this, but be mindful if you create custom components."
  },
  {
    "objectID": "advanced.html#configuration-based-setup",
    "href": "advanced.html#configuration-based-setup",
    "title": "Advanced Usage",
    "section": "",
    "text": "While you can instantiate OmniQ components directly, a configuration-driven approach offers greater flexibility, especially in production environments. This allows you to define your setup in YAML files, dictionaries, or even environment variables, decoupling your application logic from your infrastructure setup.\n\n\nFor maximum clarity and maintainability, we recommend using a YAML file to define your OmniQ setup. This approach allows you to specify the project name, task queue, result store, and worker settings in a single, easy-to-read file.\nHere’s an example of a config.yaml file:\nproject_name: production_app\n\ntask_queue:\n  type: file\n  config:\n    base_dir: ./omniq_data/tasks\n    queues:\n      - high_priority\n      - default\n      - low_priority\n\nresult_store:\n  type: sqlite\n  config:\n    base_dir: ./omniq_data/results\n\nworker:\n  type: thread_pool\n  config:\n    max_workers: 10\nYou can then load this configuration and create an OmniQ instance with a single command:\nfrom omniq import OmniQ\n\n# Load the configuration from the YAML file\noq = OmniQ.from_config_file(\"config.yaml\")\n\n# Now your OmniQ instance is ready to use\nwith oq:\n    # Enqueue tasks, manage workers, etc.\n    pass\n\n\n\nFor cloud-native applications and CI/CD pipelines, you can override configuration settings using environment variables. OmniQ recognizes variables prefixed with OMNIQ_.\nFor example, to override the worker’s max_workers setting, you can set the following environment variable:\nexport OMNIQ_WORKER_CONFIG_MAX_WORKERS=20\nOmniQ will automatically detect and apply this setting. For more details on configuration loading and precedence, see the configuration API documentation."
  },
  {
    "objectID": "advanced.html#handling-sync-and-async-tasks",
    "href": "advanced.html#handling-sync-and-async-tasks",
    "title": "Advanced Usage",
    "section": "",
    "text": "Modern applications often require a mix of synchronous (CPU-bound) and asynchronous (I/O-bound) tasks. OmniQ’s workers are designed to handle both types of tasks seamlessly within the same queue, simplifying your architecture.\nBoth ThreadWorker and AsyncWorker can execute sync and async functions without any special configuration. The worker automatically detects whether a task function is a coroutine and executes it accordingly.\nimport asyncio\nimport time\nfrom omniq import OmniQ\nfrom omniq.queue import FileTaskQueue\n\n# A standard synchronous function\ndef sync_task(x, y):\n    print(f\"Executing sync task: {x} * {y}\")\n    time.sleep(0.1)\n    return x * y\n\n# An asynchronous function\nasync def async_task(x, y):\n    print(f\"Executing async task: {x} + {y}\")\n    await asyncio.sleep(0.1)\n    return x + y\n\n# Setup OmniQ (can be done via config file as well)\noq = OmniQ(project_name=\"mixed_tasks_example\")\n\nwith oq:\n    # Enqueue both types of tasks\n    sync_task_id = oq.enqueue(sync_task, func_args={'x': 5, 'y': 10})\n    async_task_id = oq.enqueue(async_task, func_args={'x': 5, 'y': 10})\n\n    # Wait for results\n    time.sleep(1)\n\n    # Retrieve results - the worker handles both correctly\n    sync_result = oq.get_result(sync_task_id)    # -&gt; 50\n    async_result = oq.get_result(async_task_id) # -&gt; 15\n\n    print(f\"Sync Result: {sync_result}\")\n    print(f\"Async Result: {async_result}\")\nThis flexibility allows you to build versatile applications that can handle a wide variety of workloads without needing separate task processing systems."
  },
  {
    "objectID": "advanced.html#cloud-storage-with-fsspec",
    "href": "advanced.html#cloud-storage-with-fsspec",
    "title": "Advanced Usage",
    "section": "",
    "text": "OmniQ’s FileTaskQueue and FileResultStorage components are built on top of the fsspec (Filesystem Spec) library. This powerful abstraction allows you to use virtually any storage backend that fsspec supports, including cloud storage providers like Amazon S3, Google Cloud Storage (GCS), and Azure Blob Storage.\nTo use a cloud storage backend, simply provide the appropriate URI in the base_dir and include any necessary credentials in the storage_options dictionary.\n\n\nFirst, ensure you have the required library installed:\npip install s3fs\nThen, configure the FileTaskQueue to use an S3 bucket:\nfrom omniq.queue import FileTaskQueue\n\n# Configuration for S3 storage\ns3_queue = FileTaskQueue(\n    project_name=\"s3_demo\",\n    base_dir=\"s3://your-cool-bucket/omniq/tasks\",\n    storage_options={\n        \"key\": \"YOUR_AWS_ACCESS_KEY_ID\",\n        \"secret\": \"YOUR_AWS_SECRET_ACCESS_KEY\",\n    }\n)\n\n# You can now use this queue with your OmniQ instance\n# oq = OmniQ(project_name=\"s3_demo\", task_queue=s3_queue, ...)\nThe same principle applies to FileResultStorage and other cloud providers like GCS (gs://...) and Azure Blob Storage (abfs://...).\nThis integration makes it easy to build distributed, scalable applications where tasks and results are persisted in a centralized, durable, and highly-available cloud storage service."
  },
  {
    "objectID": "advanced.html#performance-tips",
    "href": "advanced.html#performance-tips",
    "title": "Advanced Usage",
    "section": "",
    "text": "Choose the Right Worker: Use ThreadWorker for I/O-bound synchronous tasks. For async tasks, AsyncWorker is generally more efficient as it can handle thousands of concurrent operations with a small number of threads.\nSerialization: The default serializer (dill) is very flexible but may not be the fastest. For performance-critical applications with well-defined data structures, consider using a faster serializer like msgspec.\nBatching: When enqueuing a large number of tasks, consider using enqueue_many to reduce the overhead of individual network requests or disk I/O operations.\nPersistent Connections: When using network-based backends (like Redis or a database), ensure your application manages connections efficiently. OmniQ’s built-in components handle this, but be mindful if you create custom components."
  }
]